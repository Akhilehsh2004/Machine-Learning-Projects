{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b41ab8c9-a3f1-4f35-83de-613bdfbaf1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 328.2ms\n",
      "Speed: 5.3ms preprocess, 328.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 219.7ms\n",
      "Speed: 3.6ms preprocess, 219.7ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 261.0ms\n",
      "Speed: 4.4ms preprocess, 261.0ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 234.2ms\n",
      "Speed: 3.7ms preprocess, 234.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 204.2ms\n",
      "Speed: 3.3ms preprocess, 204.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 197.6ms\n",
      "Speed: 3.6ms preprocess, 197.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 250.4ms\n",
      "Speed: 4.5ms preprocess, 250.4ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 244.9ms\n",
      "Speed: 4.1ms preprocess, 244.9ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 283.3ms\n",
      "Speed: 5.1ms preprocess, 283.3ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 266.4ms\n",
      "Speed: 3.7ms preprocess, 266.4ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cat, 253.4ms\n",
      "Speed: 2.5ms preprocess, 253.4ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-1712 (speak_thread):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\jagda\\AppData\\Local\\Temp\\ipykernel_6812\\528868040.py\", line 32, in speak_thread\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\site-packages\\pyttsx3\\engine.py\", line 180, in runAndWait\n",
      "    raise RuntimeError('run loop already started')\n",
      "RuntimeError: run loop already started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 cat, 276.1ms\n",
      "Speed: 3.6ms preprocess, 276.1ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-1713 (speak_thread):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\jagda\\AppData\\Local\\Temp\\ipykernel_6812\\528868040.py\", line 32, in speak_thread\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\site-packages\\pyttsx3\\engine.py\", line 180, in runAndWait\n",
      "    raise RuntimeError('run loop already started')\n",
      "RuntimeError: run loop already started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 1 cat, 1 tie, 245.6ms\n",
      "Speed: 3.7ms preprocess, 245.6ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-1714 (speak_thread):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\jagda\\AppData\\Local\\Temp\\ipykernel_6812\\528868040.py\", line 32, in speak_thread\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\site-packages\\pyttsx3\\engine.py\", line 180, in runAndWait\n",
      "    raise RuntimeError('run loop already started')\n",
      "RuntimeError: run loop already started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 255.6ms\n",
      "Speed: 3.2ms preprocess, 255.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 283.9ms\n",
      "Speed: 3.0ms preprocess, 283.9ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 253.6ms\n",
      "Speed: 4.0ms preprocess, 253.6ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 277.8ms\n",
      "Speed: 3.5ms preprocess, 277.8ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 265.8ms\n",
      "Speed: 4.3ms preprocess, 265.8ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 280.0ms\n",
      "Speed: 3.9ms preprocess, 280.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 272.7ms\n",
      "Speed: 3.6ms preprocess, 272.7ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 275.0ms\n",
      "Speed: 4.0ms preprocess, 275.0ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 270.1ms\n",
      "Speed: 4.2ms preprocess, 270.1ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 274.9ms\n",
      "Speed: 6.3ms preprocess, 274.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cat, 222.8ms\n",
      "Speed: 3.5ms preprocess, 222.8ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 241.4ms\n",
      "Speed: 5.0ms preprocess, 241.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 240.3ms\n",
      "Speed: 2.8ms preprocess, 240.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 285.5ms\n",
      "Speed: 3.9ms preprocess, 285.5ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 283.4ms\n",
      "Speed: 4.2ms preprocess, 283.4ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 285.0ms\n",
      "Speed: 4.1ms preprocess, 285.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 256.3ms\n",
      "Speed: 4.9ms preprocess, 256.3ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 259.9ms\n",
      "Speed: 2.8ms preprocess, 259.9ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 268.3ms\n",
      "Speed: 3.1ms preprocess, 268.3ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 272.6ms\n",
      "Speed: 4.7ms preprocess, 272.6ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 266.6ms\n",
      "Speed: 3.0ms preprocess, 266.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 258.1ms\n",
      "Speed: 4.6ms preprocess, 258.1ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 268.9ms\n",
      "Speed: 2.6ms preprocess, 268.9ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 266.9ms\n",
      "Speed: 4.1ms preprocess, 266.9ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 270.8ms\n",
      "Speed: 3.2ms preprocess, 270.8ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 275.6ms\n",
      "Speed: 4.6ms preprocess, 275.6ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 275.5ms\n",
      "Speed: 3.6ms preprocess, 275.5ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 277.7ms\n",
      "Speed: 4.8ms preprocess, 277.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 273.2ms\n",
      "Speed: 3.1ms preprocess, 273.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 282.1ms\n",
      "Speed: 3.5ms preprocess, 282.1ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 265.0ms\n",
      "Speed: 4.3ms preprocess, 265.0ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 253.7ms\n",
      "Speed: 3.2ms preprocess, 253.7ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cat, 1 tie, 296.7ms\n",
      "Speed: 3.4ms preprocess, 296.7ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cat, 1 tie, 230.0ms\n",
      "Speed: 5.8ms preprocess, 230.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 tie, 277.2ms\n",
      "Speed: 3.1ms preprocess, 277.2ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-1717 (speak_thread):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\jagda\\AppData\\Local\\Temp\\ipykernel_6812\\528868040.py\", line 32, in speak_thread\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\site-packages\\pyttsx3\\engine.py\", line 180, in runAndWait\n",
      "    raise RuntimeError('run loop already started')\n",
      "RuntimeError: run loop already started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 tie, 264.4ms\n",
      "Speed: 3.6ms preprocess, 264.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 207.4ms\n",
      "Speed: 3.9ms preprocess, 207.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 tie, 259.8ms\n",
      "Speed: 2.8ms preprocess, 259.8ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 267.4ms\n",
      "Speed: 4.6ms preprocess, 267.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 268.2ms\n",
      "Speed: 3.6ms preprocess, 268.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 286.5ms\n",
      "Speed: 2.2ms preprocess, 286.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 283.0ms\n",
      "Speed: 3.8ms preprocess, 283.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 284.8ms\n",
      "Speed: 3.8ms preprocess, 284.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 294.6ms\n",
      "Speed: 6.7ms preprocess, 294.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 289.4ms\n",
      "Speed: 3.0ms preprocess, 289.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 280.7ms\n",
      "Speed: 7.7ms preprocess, 280.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 268.7ms\n",
      "Speed: 3.8ms preprocess, 268.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 291.6ms\n",
      "Speed: 2.7ms preprocess, 291.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 305.2ms\n",
      "Speed: 3.5ms preprocess, 305.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 317.1ms\n",
      "Speed: 4.7ms preprocess, 317.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 280.9ms\n",
      "Speed: 4.8ms preprocess, 280.9ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cat, 266.7ms\n",
      "Speed: 3.1ms preprocess, 266.7ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cat, 303.7ms\n",
      "Speed: 3.6ms preprocess, 303.7ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 302.3ms\n",
      "Speed: 4.9ms preprocess, 302.3ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 217.7ms\n",
      "Speed: 3.7ms preprocess, 217.7ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 225.2ms\n",
      "Speed: 3.9ms preprocess, 225.2ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 207.0ms\n",
      "Speed: 2.8ms preprocess, 207.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 243.3ms\n",
      "Speed: 3.4ms preprocess, 243.3ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 276.7ms\n",
      "Speed: 3.3ms preprocess, 276.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 275.0ms\n",
      "Speed: 4.8ms preprocess, 275.0ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 282.3ms\n",
      "Speed: 2.2ms preprocess, 282.3ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 276.5ms\n",
      "Speed: 3.2ms preprocess, 276.5ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 263.7ms\n",
      "Speed: 3.4ms preprocess, 263.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cat, 1 tie, 1 refrigerator, 1 scissors, 279.5ms\n",
      "Speed: 3.1ms preprocess, 279.5ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-1719 (speak_thread):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\jagda\\AppData\\Local\\Temp\\ipykernel_6812\\528868040.py\", line 32, in speak_thread\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\site-packages\\pyttsx3\\engine.py\", line 180, in runAndWait\n",
      "    raise RuntimeError('run loop already started')\n",
      "RuntimeError: run loop already started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 train, 279.9ms\n",
      "Speed: 4.3ms preprocess, 279.9ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 288.8ms\n",
      "Speed: 4.3ms preprocess, 288.8ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 1 tie, 270.2ms\n",
      "Speed: 3.1ms preprocess, 270.2ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-1720 (speak_thread):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\jagda\\AppData\\Local\\Temp\\ipykernel_6812\\528868040.py\", line 32, in speak_thread\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\site-packages\\pyttsx3\\engine.py\", line 180, in runAndWait\n",
      "    raise RuntimeError('run loop already started')\n",
      "RuntimeError: run loop already started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 train, 1 tie, 226.5ms\n",
      "Speed: 3.3ms preprocess, 226.5ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 1 tie, 216.3ms\n",
      "Speed: 3.0ms preprocess, 216.3ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 215.3ms\n",
      "Speed: 3.5ms preprocess, 215.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 298.6ms\n",
      "Speed: 3.3ms preprocess, 298.6ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 1 tie, 263.2ms\n",
      "Speed: 2.9ms preprocess, 263.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 225.1ms\n",
      "Speed: 4.0ms preprocess, 225.1ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 233.7ms\n",
      "Speed: 3.6ms preprocess, 233.7ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 1 tie, 230.8ms\n",
      "Speed: 5.0ms preprocess, 230.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 1 tie, 265.3ms\n",
      "Speed: 3.0ms preprocess, 265.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 1 tie, 288.6ms\n",
      "Speed: 3.8ms preprocess, 288.6ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 288.7ms\n",
      "Speed: 4.0ms preprocess, 288.7ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 1 tie, 271.5ms\n",
      "Speed: 4.4ms preprocess, 271.5ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 1 tie, 277.0ms\n",
      "Speed: 3.4ms preprocess, 277.0ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 1 tie, 284.2ms\n",
      "Speed: 4.4ms preprocess, 284.2ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 279.3ms\n",
      "Speed: 4.5ms preprocess, 279.3ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 1 tie, 273.8ms\n",
      "Speed: 3.5ms preprocess, 273.8ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 1 tie, 278.6ms\n",
      "Speed: 4.3ms preprocess, 278.6ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 1 tie, 301.1ms\n",
      "Speed: 4.2ms preprocess, 301.1ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 1 tie, 301.4ms\n",
      "Speed: 4.2ms preprocess, 301.4ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 1 tie, 290.7ms\n",
      "Speed: 3.7ms preprocess, 290.7ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 1 tie, 277.9ms\n",
      "Speed: 5.2ms preprocess, 277.9ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 1 cat, 1 tie, 281.3ms\n",
      "Speed: 3.8ms preprocess, 281.3ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 231.7ms\n",
      "Speed: 7.1ms preprocess, 231.7ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 train, 1 tie, 244.4ms\n",
      "Speed: 4.2ms preprocess, 244.4ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 211.9ms\n",
      "Speed: 3.3ms preprocess, 211.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cat, 1 tie, 240.4ms\n",
      "Speed: 3.2ms preprocess, 240.4ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 tie, 258.3ms\n",
      "Speed: 3.5ms preprocess, 258.3ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 tie, 262.0ms\n",
      "Speed: 3.5ms preprocess, 262.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 tie, 204.6ms\n",
      "Speed: 3.0ms preprocess, 204.6ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 tie, 246.3ms\n",
      "Speed: 3.2ms preprocess, 246.3ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 tie, 269.8ms\n",
      "Speed: 5.0ms preprocess, 269.8ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 267.1ms\n",
      "Speed: 3.6ms preprocess, 267.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 261.4ms\n",
      "Speed: 4.0ms preprocess, 261.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 257.9ms\n",
      "Speed: 3.6ms preprocess, 257.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 272.9ms\n",
      "Speed: 5.1ms preprocess, 272.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cat, 261.2ms\n",
      "Speed: 3.5ms preprocess, 261.2ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cat, 266.3ms\n",
      "Speed: 3.2ms preprocess, 266.3ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cat, 279.0ms\n",
      "Speed: 7.1ms preprocess, 279.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cat, 267.0ms\n",
      "Speed: 3.9ms preprocess, 267.0ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 262.0ms\n",
      "Speed: 4.4ms preprocess, 262.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 271.8ms\n",
      "Speed: 2.2ms preprocess, 271.8ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-1723 (speak_thread):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\jagda\\AppData\\Local\\Temp\\ipykernel_6812\\528868040.py\", line 32, in speak_thread\n",
      "  File \"C:\\Users\\jagda\\anaconda3\\Lib\\site-packages\\pyttsx3\\engine.py\", line 180, in runAndWait\n",
      "    raise RuntimeError('run loop already started')\n",
      "RuntimeError: run loop already started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 tie, 263.7ms\n",
      "Speed: 6.6ms preprocess, 263.7ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 3 ties, 269.1ms\n",
      "Speed: 4.1ms preprocess, 269.1ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 223.9ms\n",
      "Speed: 4.5ms preprocess, 223.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 277.6ms\n",
      "Speed: 3.7ms preprocess, 277.6ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 267.3ms\n",
      "Speed: 4.0ms preprocess, 267.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 270.6ms\n",
      "Speed: 3.1ms preprocess, 270.6ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 271.6ms\n",
      "Speed: 4.0ms preprocess, 271.6ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 304.4ms\n",
      "Speed: 3.0ms preprocess, 304.4ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 275.8ms\n",
      "Speed: 7.3ms preprocess, 275.8ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 297.8ms\n",
      "Speed: 2.7ms preprocess, 297.8ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 293.8ms\n",
      "Speed: 3.4ms preprocess, 293.8ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 282.3ms\n",
      "Speed: 3.0ms preprocess, 282.3ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 294.7ms\n",
      "Speed: 3.5ms preprocess, 294.7ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 311.1ms\n",
      "Speed: 5.8ms preprocess, 311.1ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 312.7ms\n",
      "Speed: 4.4ms preprocess, 312.7ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 289.9ms\n",
      "Speed: 3.3ms preprocess, 289.9ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cat, 1 tie, 298.6ms\n",
      "Speed: 3.4ms preprocess, 298.6ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cat, 1 tie, 285.7ms\n",
      "Speed: 3.3ms preprocess, 285.7ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 294.8ms\n",
      "Speed: 2.7ms preprocess, 294.8ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import threading\n",
    "import pyttsx3\n",
    "from ultralytics import YOLO\n",
    "from playsound import playsound\n",
    "from collections import deque\n",
    "\n",
    "# Load YOLOv8 model for object detection\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Initialize text-to-speech (TTS)\n",
    "tts_engine = pyttsx3.init()\n",
    "tts_engine.setProperty('rate', 160)\n",
    "\n",
    "# Assign random colors to each class\n",
    "np.random.seed(42)\n",
    "colors = {cls_id: tuple(np.random.randint(0, 255, 3).tolist()) for cls_id in range(80)}\n",
    "\n",
    "# Sound file path\n",
    "alert_sound = \"alert.wav\"\n",
    "\n",
    "# Object tracking memory (last N detections)\n",
    "object_history = deque(maxlen=10)\n",
    "\n",
    "def speak(text):\n",
    "    \"\"\"Speak text asynchronously using pyttsx3\"\"\"\n",
    "    def speak_thread():\n",
    "        tts_engine.say(text)\n",
    "        tts_engine.runAndWait()\n",
    "\n",
    "    threading.Thread(target=speak_thread, daemon=True).start()\n",
    "\n",
    "def play_alert_sound():\n",
    "    \"\"\"Play alert sound using playsound in a separate thread\"\"\"\n",
    "    def sound_thread():\n",
    "        try:\n",
    "            playsound(alert_sound)\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing sound: {e}\")\n",
    "\n",
    "    threading.Thread(target=sound_thread, daemon=True).start()\n",
    "\n",
    "def detect_objects(frame):\n",
    "    \"\"\"Detect objects using YOLOv8\"\"\"\n",
    "    results = model(frame)\n",
    "    detected_objects = set()\n",
    "\n",
    "    for result in results:\n",
    "        if hasattr(result, \"boxes\") and result.boxes is not None:\n",
    "            for box in result.boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "                conf = box.conf[0].item()\n",
    "                cls = int(box.cls[0].item())\n",
    "                class_name = model.names.get(cls, 'Unknown')\n",
    "\n",
    "                detected_objects.add(class_name)\n",
    "                color = colors.get(cls, (0, 255, 0))\n",
    "\n",
    "                # Draw bounding box and label\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                label = f\"{class_name} {conf:.2f}\"\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "                # Traffic Sign Detection\n",
    "                if class_name in [\"stop sign\", \"traffic light\", \"speed limit\"]:\n",
    "                    speak(f\"Detected {class_name}\")\n",
    "\n",
    "    # Avoid duplicate alerts\n",
    "    if detected_objects and detected_objects not in object_history:\n",
    "        object_history.append(detected_objects)\n",
    "        speak(f\"Detected: {', '.join(detected_objects)}\")\n",
    "\n",
    "    return frame\n",
    "\n",
    "def detect_lanes(frame):\n",
    "    \"\"\"Lane detection using Canny Edge and Hough Transform\"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blur, 50, 150)\n",
    "\n",
    "    height, width = frame.shape[:2]\n",
    "    mask = np.zeros_like(edges)\n",
    "    region_of_interest = np.array([[(50, height), (width // 2 - 50, height // 2), (width // 2 + 50, height // 2), (width - 50, height)]], np.int32)\n",
    "    cv2.fillPoly(mask, region_of_interest, 255)\n",
    "    \n",
    "    masked_edges = cv2.bitwise_and(edges, mask)\n",
    "\n",
    "    lines = cv2.HoughLinesP(masked_edges, 2, np.pi / 180, 100, np.array([]), minLineLength=50, maxLineGap=150)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not access webcam.\")\n",
    "else:\n",
    "    prev_time = time.time()\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Measure FPS\n",
    "        curr_time = time.time()\n",
    "        fps = 1 / (curr_time - prev_time)\n",
    "        prev_time = curr_time\n",
    "\n",
    "        # Detect objects and lanes\n",
    "        frame = detect_objects(frame)\n",
    "        frame = detect_lanes(frame)\n",
    "\n",
    "        # Display FPS and instructions\n",
    "        cv2.putText(frame, f\"FPS: {fps:.2f}\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "        cv2.putText(frame, \"Press 'q' to exit\", (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "        # Show window\n",
    "        cv2.imshow(\"Self-Driving AI\", frame)\n",
    "\n",
    "        # Quit on 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
